{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d141b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first file will import the key data required for the study. \n",
    "# FLUXNET data is imported along with additional information on\n",
    "# the sites. \n",
    "\n",
    "### Sources ###\n",
    "\n",
    "# FLUXNET data: https://fluxnet.org\n",
    "# Additional site data: https://fluxnet.org/sites/site-list-and-pages/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce4f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import calendar\n",
    "from shapely.geometry import Point\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from pyrealm import pmodel\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import the additional site informations \n",
    "### SITE_ID, SITE_NAME, LAT, LONG\n",
    "\n",
    "site_key=pd.read_csv('/Users/abigailbase/PROJECT FILES/site_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0f091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the FLUXNET daily data for all sites\n",
    "\n",
    "df=pd.read_csv('/Users/abigailbase/PROJECT FILES/FINAL DFs/final_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaed6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign hemisphere to the points in the df. Above the equator (0) \n",
    "### is Northern Hemisphere (NH) \n",
    "\n",
    "\n",
    "def assign_hemisphere(latitude):\n",
    "    if LAT > 0:\n",
    "        return \"Northern Hemisphere\" \n",
    "    elif LONG < 0:\n",
    "        return \"Southern Hemisphere\"\n",
    "    else:\n",
    "        return \"Equator\"  # This handles the case where latitude is exactly 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign hemisphere to the points in site data \n",
    "\n",
    "site_key['hemisphere']=site_key['LAT'].apply(lambda x: 'NH' if x>=0 else 'SH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1907c443",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Map of the sites ###\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 14))\n",
    "\n",
    "map = Basemap(projection='cyl', llcrnrlat=-90, urcrnrlat=90,\n",
    "              llcrnrlon=-180, urcrnrlon=180, resolution='c', ax=ax)\n",
    "\n",
    "map.drawcoastlines()\n",
    "\n",
    "# assign colors based on the hemisphere\n",
    "colors = site_key['hemisphere'].map({\n",
    "    'NH': 'red',\n",
    "    'SH': 'blue'\n",
    "})\n",
    "\n",
    "# plot the sites\n",
    "map.scatter(site_key['LONG'], site_key['LAT'], marker='v', c=colors, edgecolor='black', s=140)\n",
    "\n",
    "\n",
    "# draw parallels and meridians\n",
    "parallels = np.arange(-90., 91., 30.)\n",
    "meridians = np.arange(-180., 181., 60.)\n",
    "map.drawparallels(parallels, labels=[1, 0, 0, 0], linewidth=0.5, color='grey')\n",
    "map.drawmeridians(meridians, labels=[0, 0, 0, 1], linewidth=0.5, color='grey')\n",
    "\n",
    "\n",
    "# legend\n",
    "dummy_scatter_north = plt.scatter([], [], color='red', marker='v', s=200, edgecolors='black', label='Northern Hemisphere')\n",
    "dummy_scatter_south = plt.scatter([], [], color='blue', marker='v', s=200, edgecolors='black', label='Southern Hemisphere')\n",
    "\n",
    "\n",
    "legend = plt.legend(handles=[dummy_scatter_north, dummy_scatter_south], loc='lower left', fontsize=18)\n",
    "legend.set_title(\"FLUXNET Sites\", prop={'size': 20, 'weight': 'bold'})\n",
    "\n",
    "\n",
    "\n",
    "frame = legend.get_frame()\n",
    "frame.set_edgecolor('black')      \n",
    "frame.set_linewidth(1.5)          \n",
    "frame.set_alpha(1)                \n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc933c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "### select the variables of interest ###\n",
    "\n",
    "\n",
    "final_df=df[['TIMESTAMP','SITE_ID','TA_F','PA_F','VPD_F','P_F','WS_F',\n",
    "            'PPFD_IN','PPFD_OUT','CO2_F_MDS','TS_F_MDS_1',\n",
    "           'SWC_F_MDS_1','NEE_VUT_REF','GPP_DT_VUT_REF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d3a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a835fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['TIMESTAMP'].dtype #check data type = int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee29a20e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### investigate the dates to see the format\n",
    "\n",
    "print(final_df['TIMESTAMP'].unique().tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### There were datapoints which had the format YYYY%MM% so these\n",
    "### were seperated out \n",
    "\n",
    "### seperate the data into 2 dfs for the differing datatime format \n",
    "\n",
    "def identify_format(date_str):\n",
    "    if len(date_str) == 8:  #YYYY%MM%DD \n",
    "        return 'full_date'\n",
    "    elif len(date_str) == 6:  #YYYY%MM \n",
    "        return 'month_year'\n",
    "    else:\n",
    "        return 'invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe52f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df=final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98824942",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df['TIMESTAMP'] = date_df['TIMESTAMP'].astype(str) #convert the date to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127c1e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df['TIMESTAMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy column to flag the date type\n",
    "\n",
    "date_df['date_type']=date_df['TIMESTAMP'].apply(identify_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6e84ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date=date_df[date_df['date_type']=='full_date'] #YYYY%MM%DD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd81fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_year=date_df[date_df['date_type']=='month_year'] #YYYY%MM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6263c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef695a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date=full_date.drop(columns='date_type') #drop the dummy col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b424876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date['TIMESTAMP']=full_date['TIMESTAMP'].astype(int) #convert date to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1f8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date['TIMESTAMP'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993011c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### convert the date to pandas datetime \n",
    "\n",
    "full_date['TIMESTAMP'] = pd.to_datetime(full_date['TIMESTAMP'], format='%Y%m%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8cfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date['TIMESTAMP'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c955461",
   "metadata": {},
   "outputs": [],
   "source": [
    "### extract the year, month and day for full_date\n",
    "\n",
    "full_date.loc[:, 'YEAR'] = full_date['TIMESTAMP'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03e6667",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date.loc[:, 'MONTH'] = full_date['TIMESTAMP'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d60e704",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date.loc[:, 'DAY'] = full_date['TIMESTAMP'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e922c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop the timestamp column\n",
    "\n",
    "full_date=full_date.drop(columns='TIMESTAMP') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f27234",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_date.isna().sum() #No missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67db931",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(full_date.shape) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c71897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the final df with the timestamp seperated out as year, month, day is saved\n",
    "# and will be imported into the next file. \n",
    "\n",
    "\n",
    "full_date.to_csv('/Users/abigailbase/PROJECT FILES/FINAL DFs/full_date.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
