{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9736e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â This file was used to concat all of the downloaded ERA5-Land data. As the data was downloaded\n",
    "# in smaller sections due to computational restraints.\n",
    "# the function combines all of the .nc files in the given directory (E.g. AR-Vir) and converts them all to dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278b8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr \n",
    "import pandas as pd\n",
    "import netCDF4 as nc \n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121df89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nc_file(file_path, filename):\n",
    "    try:\n",
    "        # extract the site_id from the filename \n",
    "        site_id = filename.split('_')[1]  \n",
    "\n",
    "        ds = xr.open_dataset(file_path)\n",
    "        df = ds.to_dataframe().reset_index()\n",
    "        df['valid_time'] = pd.to_datetime(df['valid_time']).dt.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # add  site_id column\n",
    "        df['site_id'] = site_id\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "directory_path = '/Users/abigailbase/PROJECT FILES/SSRD downloads'\n",
    "\n",
    "if not os.path.isdir(directory_path):\n",
    "    print(f\"Directory does not exist: {directory_path}\")\n",
    "else:\n",
    "    # empty list to hold dfs\n",
    "    df_list = []\n",
    "\n",
    "    # iterate over files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".nc\"):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            df = process_nc_file(file_path, filename)\n",
    "            if df is not None:\n",
    "                df_list.append(df)\n",
    "            else:\n",
    "                print(f\"Skipped {file_path} due to processing error.\")\n",
    "    \n",
    "    if df_list:\n",
    "        # Concatenate all DataFrames in the list into a single DataFrame\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        \n",
    "        # save the df to  CSV \n",
    "        combined_df.to_csv('SSRD.csv', index=False)\n",
    "        print(\"Combined data saved to 'SSRD.csv'.\")\n",
    "    else:\n",
    "        print(\"No DataFrames to concatenate.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
